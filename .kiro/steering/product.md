# AI批改效果分析平台

## 产品定位
面向AI批改产品的效果分析平台，用于量化评估AI批改的准确性、效率和资源消耗。

## 核心功能模块

### 测试计划看板 (`/` 首页)
- **概览统计**: 数据集总数、任务数(今日/本周/本月)、已测题目数、整体准确率及趋势
- **批量任务列表**: 分页展示、状态筛选、准确率显示
- **数据集概览**: 使用次数、历史准确率、难度标签(简单/中等/困难)
- **学科评估概览**: 按学科聚合统计，低于80%准确率标红警告
- **测试计划管理**: 创建/编辑/删除/克隆/启动计划
- **AI生成测试计划**: 基于数据集内容自动生成计划建议
- **内存缓存**: 5分钟TTL缓存，支持手动刷新

### 批量评估 (`/batch-evaluation`)
- 上传基准答案与AI批改结果进行对比分析
- 支持Excel文件批量导入
- 计算准确率、精确率、召回率、F1值
- 数据集选择: 同一页码可关联多个数据集，支持切换
- 批量选择: 可为多个作业批量指定数据集
- 学科匹配规则:
  - 语文(subject_id=1): 按题号(index)匹配
  - 其他学科: 按tempIndex匹配

### 高级分析功能
- **批量对比**: 多任务准确率对比、趋势图表
- **异常检测**: 自动识别准确率异常波动
- **聚类分析**: 按错误类型/学科聚类分析
- **下钻分析**: 多维度数据钻取(学科→书本→页码→题目)
- **错误样本管理**: 错误标记和样本导出
- **错误关联分析**: 错误类型关联分析
- **最佳实践推荐**: 基于历史数据推荐优化方案
- **优化建议**: 自动生成优化建议

### 协作与自动化
- **自动化调度**: 支持 daily/weekly/cron 定时执行评估任务
- **任务分配**: 团队协作，分配任务给指定成员
- **保存筛选器**: 保存常用筛选条件，快速复用

### 学科批改 (`/subject-grading`)
- 多学科作业图片识别和批改效果评估
- 支持数学、英语、语文、物理、化学等学科
- 实时批改和效果统计

### 知识点类题生成 (`/knowledge-agent`)
- 从作业图片提取知识点
- 基于知识点生成类似题目
- 支持题目去重和导出

### 数据分析 (`/data-analysis`)
- 可视化展示评估结果和统计数据
- 多维度数据对比
- 趋势分析

### 数据集管理 (`/dataset-manage`)
- 管理评估数据集（基准效果）
- 支持数据集自定义命名和描述
- 默认名称格式: `{书名}_P{页码范围}_{时间戳}`
- 重复检测: 相同书本+页码组合提示已存在数据集
- 支持按名称模糊搜索
- 向后兼容: 旧数据集自动生成默认名称

### Prompt调优 (`/prompt-optimize`)
- 优化AI批改提示词
- A/B测试不同Prompt效果
- Prompt版本管理

### 多模型对比 (`/compare`)
- 支持不同AI模型的批改效果对比
- 实时对话对比
- 效果指标对比

## 学科ID映射
| subject_id | 学科 |
|------------|------|
| 0 | 英语 |
| 1 | 语文 |
| 2 | 数学 |
| 3 | 物理 |
| 4 | 化学 |
| 5 | 生物 |
| 6 | 地理 |

## 用户场景
- 验证AI批改产品是否符合效果标准
- 对比不同版本/模型的批改效果
- 优化算法降低错误率、耗时、Token成本

## 评估维度
- 准确性: 准确率、精确率、召回率、F1值
- 效率: 单题/批量批改耗时
- 资源: Token消耗量和成本
- 错误分类: 识别错误、判断错误、格式差异、AI幻觉等
